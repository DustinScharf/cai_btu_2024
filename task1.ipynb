{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pjXcJsPfdJq",
    "outputId": "0a2bce10-a1ac-46a6-ebcc-af24a4e71a77",
    "ExecuteTime": {
     "end_time": "2024-10-31T17:06:57.210123Z",
     "start_time": "2024-10-31T17:06:57.203173Z"
    }
   },
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# An introduction to artificial intelligence and its impact on various fields.\n",
    "text = \"Artificial Intelligence (AI) is a rapidly evolving field that seeks to create systems capable of performing tasks that typically require human intelligence. From autonomous vehicles to personalized recommendations, AI technologies are transforming industries such as healthcare, finance, education, and entertainment. Machine learning, a subset of AI, enables systems to learn from data and improve over time, while deep learning uses neural networks to tackle complex problems. Despite its benefits, AI also raises ethical concerns, particularly around privacy, employment, and the potential for biased decision-making. As AI continues to advance, it will play an increasingly significant role in shaping the future of society.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Print the tokens\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Print the token count\n",
    "print(f\"Total Tokens: {len(tokens)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Calculate the frequencies\n",
    "fdist = nltk.FreqDist()\n",
    "for word in tokens:\n",
    "  fdist[word.lower()] += 1\n",
    "\n",
    "# Print tokens sorted by frequency with their occurrences\n",
    "print(\"Token Frequencies:\")\n",
    "for word, freq in fdist.most_common():\n",
    "  print(f\"{word:<15} {freq}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Artificial', 'Intelligence', '(', 'AI', ')', 'is', 'a', 'rapidly', 'evolving', 'field', 'that', 'seeks', 'to', 'create', 'systems', 'capable', 'of', 'performing', 'tasks', 'that', 'typically', 'require', 'human', 'intelligence', '.', 'From', 'autonomous', 'vehicles', 'to', 'personalized', 'recommendations', ',', 'AI', 'technologies', 'are', 'transforming', 'industries', 'such', 'as', 'healthcare', ',', 'finance', ',', 'education', ',', 'and', 'entertainment', '.', 'Machine', 'learning', ',', 'a', 'subset', 'of', 'AI', ',', 'enables', 'systems', 'to', 'learn', 'from', 'data', 'and', 'improve', 'over', 'time', ',', 'while', 'deep', 'learning', 'uses', 'neural', 'networks', 'to', 'tackle', 'complex', 'problems', '.', 'Despite', 'its', 'benefits', ',', 'AI', 'also', 'raises', 'ethical', 'concerns', ',', 'particularly', 'around', 'privacy', ',', 'employment', ',', 'and', 'the', 'potential', 'for', 'biased', 'decision-making', '.', 'As', 'AI', 'continues', 'to', 'advance', ',', 'it', 'will', 'play', 'an', 'increasingly', 'significant', 'role', 'in', 'shaping', 'the', 'future', 'of', 'society', '.']\n",
      "------------------------------\n",
      "Total Tokens: 121\n",
      "------------------------------\n",
      "Token Frequencies:\n",
      ",               12\n",
      "ai              5\n",
      "to              5\n",
      ".               5\n",
      "of              3\n",
      "and             3\n",
      "intelligence    2\n",
      "a               2\n",
      "that            2\n",
      "systems         2\n",
      "from            2\n",
      "as              2\n",
      "learning        2\n",
      "the             2\n",
      "artificial      1\n",
      "(               1\n",
      ")               1\n",
      "is              1\n",
      "rapidly         1\n",
      "evolving        1\n",
      "field           1\n",
      "seeks           1\n",
      "create          1\n",
      "capable         1\n",
      "performing      1\n",
      "tasks           1\n",
      "typically       1\n",
      "require         1\n",
      "human           1\n",
      "autonomous      1\n",
      "vehicles        1\n",
      "personalized    1\n",
      "recommendations 1\n",
      "technologies    1\n",
      "are             1\n",
      "transforming    1\n",
      "industries      1\n",
      "such            1\n",
      "healthcare      1\n",
      "finance         1\n",
      "education       1\n",
      "entertainment   1\n",
      "machine         1\n",
      "subset          1\n",
      "enables         1\n",
      "learn           1\n",
      "data            1\n",
      "improve         1\n",
      "over            1\n",
      "time            1\n",
      "while           1\n",
      "deep            1\n",
      "uses            1\n",
      "neural          1\n",
      "networks        1\n",
      "tackle          1\n",
      "complex         1\n",
      "problems        1\n",
      "despite         1\n",
      "its             1\n",
      "benefits        1\n",
      "also            1\n",
      "raises          1\n",
      "ethical         1\n",
      "concerns        1\n",
      "particularly    1\n",
      "around          1\n",
      "privacy         1\n",
      "employment      1\n",
      "potential       1\n",
      "for             1\n",
      "biased          1\n",
      "decision-making 1\n",
      "continues       1\n",
      "advance         1\n",
      "it              1\n",
      "will            1\n",
      "play            1\n",
      "an              1\n",
      "increasingly    1\n",
      "significant     1\n",
      "role            1\n",
      "in              1\n",
      "shaping         1\n",
      "future          1\n",
      "society         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dustin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "id": "7S0wDXy9lIyc"
   }
  }
 ]
}
